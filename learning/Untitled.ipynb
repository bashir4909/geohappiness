{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess tweets\n",
    "import sys, csv\n",
    "sys.path.append('modules/')\n",
    "from wordcount import mk_words\n",
    "sentences = []\n",
    "labels = []\n",
    "with open('tweets.csv') as fp:\n",
    "    csv_r = csv.reader(fp)\n",
    "    for row in csv_r:\n",
    "        try:\n",
    "            score = float(row[2])\n",
    "            labels.append(score)\n",
    "        except:\n",
    "            continue\n",
    "        sentence = row[1]\n",
    "        words = mk_words(sentence)\n",
    "        sentences.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create word2vec model\n",
    "model = Word2Vec(sentences, min_count=10, size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "def ave_vectors(vector_list, size):\n",
    "    sum_vector = np.zeros(size)\n",
    "    for vector in vector_list:\n",
    "        sum_vector += vector\n",
    "    if (len(vector_list) == 0):\n",
    "        length = 1\n",
    "    else:\n",
    "        length = len(vector_list)\n",
    "    return(1.0*sum_vector / length)\n",
    "\n",
    "def sentence_vector(words):\n",
    "    #average all words in sentence to one vectorf\n",
    "#     words = mk_words(sentence)\n",
    "    word_vectors = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            word_vectors.append(model.wv[word])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return ave_vectors(word_vectors, 300)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(858,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create training and testing vector list\n",
    "sentences_vec = list(map(sentence_vector, sentences))\n",
    "n = len(sentences)\n",
    "training_sent_arr = np.array(sentences_vec[:int(0.8*n)])\n",
    "testing_sent_arr = np.array(sentences_vec[int(0.8*n):])\n",
    "training_label_arr = np.array(labels[:int(0.8*n)])\n",
    "testing_label_arr = np.array(labels[int(0.8*n):])\n",
    "testing_label_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create linear regressor\n",
    "lr = LinearRegression()\n",
    "lr.fit(training_sent_arr, training_label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5699300699300699\n"
     ]
    }
   ],
   "source": [
    "res = lr.predict(testing_sent_arr)\n",
    "succes = 0\n",
    "for i in range(0, res.size):\n",
    "    diff = (res[i] - testing_label_arr[i])**2\n",
    "    if diff <= 0.001:\n",
    "        succes += 1\n",
    "print(succes / res.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make labels suitable of MLP classifier\n",
    "# values of boundaries has been determined by manual analysis\n",
    "boundaries =[\n",
    "    0.23,\n",
    "    0.1958,\n",
    "    0.1680,\n",
    "    0.1475\n",
    "]\n",
    "def get_lbl(x):\n",
    "    if x>boundaries[0]:\n",
    "        return 4\n",
    "    elif x<boundaries[3]:\n",
    "        return 0\n",
    "    elif x<boundaries[1]:\n",
    "        return 3\n",
    "    elif x<boundaries[2]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def get_vec(score):\n",
    "    lbl = get_lbl(score)\n",
    "    vector = [0,0,0,0,0]\n",
    "    vector[lbl] = 1\n",
    "    return np.array(vector)\n",
    "\n",
    "label_vectors = [get_vec(score) for score in labels]\n",
    "n = len(label_vectors)\n",
    "training_label_arr = np.array(label_vectors[:int(0.8*n)])\n",
    "testing_label_arr = np.array(label_vectors[int(0.2*n):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let us try multi layer neural networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlpr = MLPClassifier()\n",
    "mlpr.fit(training_sent_arr, training_label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpr.predict([testing_sent_arr[20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
