{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>üòç</td>\n",
       "      <td>0.158883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>üò≠</td>\n",
       "      <td>0.102536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I fucking love you, @Lesdoggg\\n\\nI really just...</td>\n",
       "      <td>0.143170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bruno Mars - Live In Harlem is incredible. Coo...</td>\n",
       "      <td>0.145217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sass level: expert üòÇ https://t.co/TLiSWbUyzt</td>\n",
       "      <td>0.125484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                  0         1\n",
       "0           0                                                  üòç  0.158883\n",
       "1           1                                                  üò≠  0.102536\n",
       "2           2  I fucking love you, @Lesdoggg\\n\\nI really just...  0.143170\n",
       "3           3  Bruno Mars - Live In Harlem is incredible. Coo...  0.145217\n",
       "4           4       Sass level: expert üòÇ https://t.co/TLiSWbUyzt  0.125484"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twtdata = pd.read_csv('tweet_training.csv')\n",
    "twtdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from labeler import Labeler\n",
    "\n",
    "class Predicter(BernoulliNB):\n",
    "    \n",
    "    # accept training data set as 2-column DataFrame\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    # give dictionary to the labeler to be initiated\n",
    "    def init_labeler(self, dictionary):\n",
    "        self.labeler = Labeler(dictionary)\n",
    "    \n",
    "    # now that labeler can vectorize our sentences\n",
    "    # we are ready to train our model\n",
    "    # df[0] -> sentences\n",
    "    # df[1] -> scores\n",
    "    def train(self, sentence_list, labels):\n",
    "        \n",
    "        feature_vector = (self.labeler\n",
    "                          .label_sentence_list(sentence_list))\n",
    "#         print(feature_vector.iloc[10].size)\n",
    "#         print((scores))\n",
    "        super().fit(feature_vector, labels)\n",
    "    \n",
    "    def test(self, sentences, real_values):\n",
    "        # sentences -> pandas Series of sentences\n",
    "        test_vector = self.labeler.label_sentence_list(sentences)\n",
    "        test_results = super().predict(test_vector)\n",
    "        # analyze the results\n",
    "        df_temp = pd.concat([test_results, real_values], axis=1)\n",
    "        hit_rate = (df_temp\n",
    "                    .apply(lambda row:1 if row[0] == row[1] else 0, axis=1)\n",
    "                    .sum())*1.0 / test_results.size\n",
    "        return hit_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>https</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>happy</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>love</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299</th>\n",
       "      <td>day</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>edinburgh</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          index    0\n",
       "1920      https  675\n",
       "4922      happy  130\n",
       "2113       love  107\n",
       "5299        day  106\n",
       "2172  edinburgh   98"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wordcount import Stats\n",
    "\n",
    "# get sentences and process them into dictionary words\n",
    "sentences = dataset.iloc[:,0]\n",
    "stats = Stats()\n",
    "word_freq = stats.process_pd_series(sentences)\n",
    "# conver dictionary into DataFrame and sort it\n",
    "# reset index so that words are stored as column as well\n",
    "df_word_freq = pd.DataFrame.from_dict(word_freq, orient='index').reset_index()\n",
    "df_word_freq = df_word_freq.sort_values(0, ascending=False)\n",
    "df_word_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bashir/Documents/geohappiness/venv/lib/python3.5/site-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# find words which occur more than 5 less than 200\n",
    "ready_dict = df_word_freq[df_word_freq[0]>5][df_word_freq[0]<200]\n",
    "# save dictionary as csv for future use\n",
    "ready_dict['index'].to_csv('dictionary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happy', 'love', 'day', 'edinburgh', 'thank', 'birthday', 'just', 'good', 'hope', 'new', 'best', 'thanks', 'like', 've', 'time', 'amp', 'today', 'night', 'united', 'kingdom', 'xx', 'got', 'xxx', 'scotland', 'great', 'man', 'work', 'wee', 'don', 'really', 'amazing', 'friday', 'valentine', 'week', 'baby', 'soon', 'oh', 'know', 'tomorrow', 'need', 'll', 'ned_stevens1', 'big', 'weekend', 'come', 'going', 'year', 'ur', 'better', 'morning', 'mate', 'wait', 'luv', 'nice', 'tonight', 'look', 'lovely', 'make', 'way', 'having', 'valentines', 'right', 'scottish', 'actually', 'fucking', 'sure', 'cheers', 'wow', 'beautiful', 'miss', 'aye', 'didn', 'world', 'dan', 'life', 'brilliant', 'game', 'omg', 'people', 'away', 'getting', 'want', 'looking', 'bit', 'watch', 'old', 'absolute', 'said', 'live', 'say', 'absolutely', 'feeling', 'did', 'read', 'little', 'forward', 'xxxx', 'excited', 'fuck', 'think', 'ma', 'long', 'proud', 'babes', 'tweet', 'news', 'thing', 'enjoy', 'try', 'girl', 'dog', 'ellemurrayxx', 'half', 'tell', 'finally', 'fab', 'stop', 'school', 'club', 'weeks', 'eh', 'believe', 'bday', 'ya', 'guy', 'home', 'yes', 'hate', 'valentinesday', 'fans', 'days', 'team', 'uk', 'class', 'end', 'tickets', 'hard', 'sweet', 'yeah', 'hopefully', 'looks', 'let', 'hi', 'phone', 'definitely', 'face', 'lad', 'edinburghrugby', 'en', '12', 'twitter', 'boy', 'shit', 'aww', 'em', 'seen', 'cute', 'brother', 'awesome', 'honestly', 'seeing', 'times', 'evening', 'single', 'gym', 'guys', 'song', 'im', 'bad', 'bro', 'city', 'episode', 'past', 'talk', 'couldn', 'true', 'super', 'gets', 'book', 'castle', 'feel', 'set', 'win', 'place', 'photo', 'radiox', 'lol', 'months', 'date', 'realise', 'glad', 'went', 'lunch', 'things', 'gun', 'busy', 'yesterday', 'awww', 'legend', 'luck', 'ha', 'edinburghcastle', 'bed', 'making', 'training', 'haha', 'mean', 'fantastic', 'coming', 'london', 'coffee', 'sexy', '_bethanymcginnx', 'josephdevries', 'used', 'hun', 'gal', 'send', 'babe', 'gorgeous', 'mum', 'boys']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('dictionary.csv') as fp:\n",
    "    csv_r = csv.reader(fp)\n",
    "    dictionary = [ row[0] for row in list(csv_r)]\n",
    "pred = Predicter()\n",
    "pred.init_labeler(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
